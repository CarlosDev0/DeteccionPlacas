# -*- coding: utf-8 -*-
"""Detección_Placas4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iNAkpFW37cHNoDHq78l9AKqzEw_E35TG
"""


import matplotlib.pyplot as plt

from PIL import Image
import cv2 as cv2
import numpy as np

import os


ruta1 = "E:/CARLOS/"
file2 = ruta1+'Test/'    #Seleccionar Training or Test
files_names1 = os.listdir(file2)  # hace una lista de las clases
print(files_names1)

#file1 = cv2.imread(ruta1+ "/Placas/carro38.jpg")
# 38 y 52

"""ENTRENAR MODELO OCR:"""


def resize_scale(img, scale_percent):
    # scale_percent contiene el porcentaje en el que se debe escalar la imagen
    width = int(img.shape[1] * scale_percent / 100)
    height = int(img.shape[0] * scale_percent / 100)
    dim = (width, height)
    resized = cv2.resize(img, dim, interpolation=cv2.INTER_AREA)
    return resized


def resize_fix(img, dim):
    dsize = (dim, dim)
    # resize image
    resized = cv2.resize(img, dsize)
    return resized


# Falta estandarizar tamaño de imagen:

# Leer imágenes y conformar vectores

files_names1 = os.listdir(file2)  # List all directories in file2
vectr1 = []
target1 = []
etiquetas = []
etiquetasD = {}  # Diccionario
num_clase1 = 0
contador = 0
cnt = 0
for clase in files_names1:
    ruta2 = os.listdir(file2+clase)
    contador = contador+1
    etiquetas.append([contador, clase])
    etiquetasD[contador] = [clase]
    # contador=0
    #print('ruta2', ruta2)
    cnt = 0
    for imagen in ruta2:
        cnt = cnt+1
        # if contador<20:
        #print('size', np.shape(imagen))
        aux = file2 + clase + '/' + imagen
        image = plt.imread(aux)
        image_ = resize_fix(image, 128)  # redimensiona a 64x64
        if cnt == 1:
            plt.imshow(image_)
            # cv2.imshow('winname',image_)
            print('Ruta: ', aux)
        if image_ is None:
            continue
        vectr1.append(image_)  # vector de vectores
        # print(vectr)
        # clasifica las imagenes de acuerdo a la clase a la que pertenecen
        target1.append(contador)

# np.save(file2+'vectr1',vectr1)
print('vectr1', vectr1)
print('target1', target1)
print('etiquetas', etiquetas)

np.save(ruta1+'/Vectors/vectr1', vectr1)
np.save(ruta1+'/Vectors/target1', target1)
np.save(ruta1+'/Vectors/etiquetasD', etiquetasD)

# Cargo los vectores
# vectr1=np.load(ruta1+'/Vectors/'+'vectr1.npy')
# target1=np.load(ruta1+'/Vectors/'+'target1.npy')

# cv2.imshow(image_)
# cv2.imshow(vectr1[36])
#file2 = ruta1 + '/Img/'
image = plt.imread(file2+'8/img009-001.png')
# cv2.imshow(image)

# Cargo los vectores
vectr1 = np.load(ruta1+'/Vectors/'+'vectr1.npy')
target1 = np.load(ruta1+'/Vectors/'+'target1.npy')
vectr_norm = []

# Normalizo el vector
# vectr_norm = vectr1/np.linalg.norm(255.0)   # Error: TypeError: ufunc 'true_divide' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''
vectr_norm = vectr1/np.linalg.norm(vectr1)

vectr_norm = np.array(vectr_norm)  # lo vuelvo un array
target1 = np.array(target1)
print('etiquetas', etiquetas)
print(len(etiquetas))
print(len(etiquetas[0]))

# Separación de la base de datos
# X_train contiene los datos del vector de vectores, del mismo tamaño que y_train
# Y_train contiene las clases a las que pertenecen (Key)
X_train2, X_test2, y_train2, y_test2 = train_test_split(
    vectr_norm, target1, test_size=0.4, random_state=0)

print(X_train2.shape, y_train2.shape, X_test2.shape, y_test2.shape)
# (numero de imagenes, ancho x alto, numero de canales)


def get_conv_model(num_classes=36, img_size=64, use_maxpooling=True, compile=True):
    print("using", num_classes, "classes")
    inputs = tf.keras.Input(shape=(img_size, img_size, 3),
                            name="input_1")  # h,w,canal
    layers = tf.keras.layers.Conv2D(30, (3, 3), activation="relu")(inputs)
    if use_maxpooling:
        layers = tf.keras.layers.MaxPool2D((2, 2), name="pooling")(layers)
    layers = tf.keras.layers.Conv2D(30, (5, 5), activation="relu")(layers)
    layers = tf.keras.layers.MaxPool2D(
        (2, 2), name="pooling2")(layers)  # 0.84  (64,3,3)
    layers = tf.keras.layers.Flatten()(layers)
    layers = tf.keras.layers.Dense(60, activation=tf.nn.relu)(layers)  # 128
    layers = tf.keras.layers.Dropout(0.2)(layers)
    predictions = tf.keras.layers.Dense(
        num_classes, activation=tf.nn.softmax, name="output_1")(layers)
    model = tf.keras.Model(inputs=inputs, outputs=predictions)
    if compile:
        model.compile(optimizer='adam',
                      loss='sparse_categorical_crossentropy',
                      metrics=['accuracy'])
    return model


modely = get_conv_model(use_maxpooling=True)
modely.summary()


def train(model, batch_size, epochs, model_name=""):
    from time import time
    tensorboard = tf.keras.callbacks.TensorBoard(
        log_dir="logs/"+model_name+"_"+"{}".format(time()))
    model.reset_states()
    model.fit(X_train2, y_train2, epochs=epochs, callbacks=[tensorboard],
              batch_size=batch_size,
              validation_data=(X_test2, y_test2))
    metrics = model.evaluate(X_test2, y_test2)
    return {k: v for k, v in zip(model.metrics_names, metrics)}


train(modely, batch_size=1024, epochs=1000, model_name="model_C")

#from local.lib import mlutils

test_preds2 = modely.predict(X_test2).argmax(axis=1)
#mlutils.plot_confusion_matrix(y_test2, test_preds2, classes=np.r_[0,1,2,3,4], normalize=True)
print('test_preds2', test_preds2)

idxs = np.random.permutation(len(X_test2))[:5]
preds = modely.predict(X_test2[idxs])
mlutils.show_preds(X_test2[idxs], y_test2[idxs], preds)

"""PARTE 1:"""

# Preprocesado de Imagen:
# Reduce Brighness
# cv2.imshow(file1)
h, s, v = cv2.split(file1)
v = cv2.subtract(v, 50)
v[v < 0] = 0
hsv = cv2.merge((h, s, v))

img_np = np.array(hsv)

# Identificar amarillas:
img_np = file1
# cv2.imshow(img_np)
nB = np.matrix(img_np[:, :, 0])
nG = np.matrix(img_np[:, :, 1])
nR = np.matrix(img_np[:, :, 2])

color = cv2.absdiff(nG, nB)  # Restar
# _,umbral = cv2.threshold(color,40,255,cv2.THRESH_BINARY) #Binariza la imagen 38
# _,umbral = cv2.threshold(color,100,255,cv2.THRESH_BINARY) #Binariza la imagen 47

# Binarización adaptativa:
imgSize = np.shape(color)
blockSize = int(1 / 8 * imgSize[0] / 2 * 2 + 1)
if blockSize <= 1:
    blockSize = int(imgSize[0] / 2 * 2 + 1)
const = 10
mask = cv2.adaptiveThreshold(
    color, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)
#mask = cv2.adaptiveThreshold(color, maxValue = 255, adaptiveMethod = cv2.ADAPTIVE_THRESH_MEAN_C, thresholdType = cv2.THRESH_BINARY, blockSize = blockSize, C = const)

# Operación Morfológica para definir bien el contorno de la máscara
kernel = np.ones((5, 5), np.uint8)
mask = cv2.dilate(mask, kernel, iterations=1)
#mask = cv2.dilate(mask, kernel, iterations=1)
#mask = cv2.erode(mask, kernel, iterations=1)
#img_erosion = cv2.erode(img_erosion, kernel, iterations=1)


print('color:')
cv2.imshow(color)
# print('mask:')
# cv2.imshow(mask)
# cv2.imshow(canvas)

[fil, col] = color.shape
for i in range(0, fil):
    for j in range(0, col):
        if color[i, j] < 80:
            color[i, j] = 0

for i in range(0, fil):
    for j in range(0, col):
        if color[i, j] > 0:
            color[i, j] = 1

color = color * 255
#print('color Segmentado:')
# cv2.imshow(color)

im2, contornos, hierarchy = cv2.findContours(
    color, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)

candidatos = []
for c in contornos:
    area = cv2.contourArea(c)
    x, y, w, h = cv2.boundingRect(c)
    epsilon = 0.09*cv2.arcLength(c, True)
    # approximate the shape of polygonal curves
    approx = cv2.approxPolyDP(c, epsilon, True)
    # print("area:",area)
    # print("approx:",len(approx))
    # if len(approx)==4 and area>4:

    if area > 1000 and area < 14000:
        print('area=', area)
        # print("approx:",len(approx))
        # cv2.drawContours(image,[approx],0,(0,255,0),3)
        aspect_ratio = float(w)/h
        print("aspect_ratio:", aspect_ratio)
        if aspect_ratio > 1.9 and aspect_ratio < 10.3:  # original: 2.07
            placa = file1[y:y+h, x:x+w]
            candidatos.append(c)
            print('placa:')
            cv2.imshow(placa)

print('SIZE_contornos: ', np.shape(contornos))
print('SIZE_candidatos: ', np.shape(np.array(candidatos, dtype=object)))


# Extracción de placa vehicular
#umbral = np.bitwise_and(color, file1[:,:,0])
#umbral = cv2.bitwise_and(file1, file1, mask=color)
#umbral = np.bitwise_and(color, file1)
# print('umbral:')
# cv2.imshow(umbral)
file1 = placa
